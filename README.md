# MSPG

Code for EHR pretraining.

- 1. Self-supervised learning from multi-modality data
- 2. Initialize prototypes
- 3. DiffEM for TS-level embedding extraction
- 4. Downstream task


### Usage 
```
git clone https://github.com/KaedeGo/MMMSPG
pip install -e .
```

### TODO

- [x] formalize dataset with different modalities
- [x] process notes
- [x] prototype learning
- [ ] double check preprocessing code, which has been run in the FairEHR repo.
- [ ] collect a large dataset for self-supervised pretraining ...
- [ ] multimodal fusion
- [ ] merge dataset preprocessing code ... maybe write a README.md to illustrate how to formulate the dataset 

### Results
XXX